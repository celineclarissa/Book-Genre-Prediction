{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "Name: Celine Clarissa\n",
    "\n",
    "Original Dataset: [Kaggle](https://www.kaggle.com/datasets/athu1105/book-genre-prediction/data).\n",
    "\n",
    "Deployment: [Hugging Face](https://huggingface.co/spaces/celineclarissa/GC7)\n",
    "\n",
    "GitHub: [GitHub Link](https://github.com/celineclarissa/Book-Genre-Prediction)\n",
    "\n",
    "---\n",
    "\n",
    "## Identifying the Problem\n",
    "\n",
    "#### `Background`\n",
    "\n",
    "I am a data scientist at a book distribution company. As a company, it is important to know the characteristics of books in order to sort books based on its genre. The information can then be used to make strategies based on book genre.\n",
    "\n",
    "#### `Problem Statement and Objectives (SMART Framework)`\n",
    " \n",
    "As a data scientist at a book distribution company, skills of training, testing, tuning, and evaluating a model are important because the company can then use the model to predict the genre of a book before accepting to distribute it. The company can then determine a business strategy like planning a choosing books to distribute based on genre, for example. This can be done by using data. After analyzing book genre characteristics from EDA, data scientist will then do feature engineering towards data. Then, data scientist will do modelling with ANN to predict genre of book. Then, data scientist will attempt to improve model. The best model is aimed to have an accuracy score of more than 90% and then deployed on HuggingFace for effective use after 7 working days. Webapp where model is deployed will also feature a page for EDA.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "# 2. Import Libraries\n",
    "The following are the libraries used in my model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tf_hub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import re\n",
    "\n",
    "# import feature engineering\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tf_hub\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 3. Loading and Defining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data scientist will now define function for text preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stopwords\n",
    "stopwords_eng = stopwords.words('english')\n",
    "\n",
    "# define text preprocessing function\n",
    "def text_preprocessing(text):\n",
    "  '''\n",
    "  This function is created to do text preprocessing: change text to lowercase, remove numbers and punctuation symbols, remove stopwords,\n",
    "  lemmatize text, and tokenize text. Text preprocessing can be done just by calling this function.\n",
    "  '''\n",
    "  # change text to lowercase\n",
    "  text = text.lower()\n",
    "\n",
    "  # remove [UNK]\n",
    "  text = text.replace('[UNK]', '')\n",
    "  text = text.replace('unk', '')\n",
    "  text = text.replace('UNK', '')\n",
    "  text = text.replace('[unk]', '')\n",
    "\n",
    "  # remove numbers\n",
    "  text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "  # remove comma\n",
    "  text = text.replace(',', '')\n",
    "\n",
    "  # remove period symbol\n",
    "  text = text.replace('.', '')\n",
    "\n",
    "  # remove exclamation mark\n",
    "  text = text.replace('!', '')\n",
    "\n",
    "  # remove question mark\n",
    "  text = text.replace('?', '')\n",
    "\n",
    "  # change texts using quotation marks that have negative connotation\n",
    "  text = text.replace(\"don't\", \"do not\")\n",
    "  text = text.replace(\"aren't\", \"are not\")\n",
    "  text = text.replace(\"isn't\", \"is not\")\n",
    "  text = text.replace(\"didn't\", \"did not\")\n",
    "  text = text.replace(\"can't\", \"cannot\")\n",
    "  text = text.replace(\"couldn't\", \"could not\")\n",
    "  text = text.replace(\"didn't\", \"did not\")\n",
    "\n",
    "  # remove quotation mark\n",
    "  text = text.replace('\"', '')\n",
    "  text = text.replace(\"'\", '')\n",
    "  text = text.replace('â€™', '')\n",
    "\n",
    "  # remove whitespace\n",
    "  text = text.strip()\n",
    "\n",
    "  # tokenization\n",
    "  tokens = word_tokenize(text)\n",
    "\n",
    "  # remove stopwords\n",
    "  tokens = [word for word in tokens if word not in stopwords_eng]\n",
    "\n",
    "  # lemmatization\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "  # combine tokens\n",
    "  text = ' '.join(tokens)\n",
    "\n",
    "  return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data scientist will use pretrained layer to improve model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pretrained layer from kaggle\n",
    "url = 'https://tfhub.dev/google/tf2-preview/nnlm-id-dim128-with-normalization/1'\n",
    "pretrained_layer = tf_hub.KerasLayer(url, output_shape=[128], input_shape=[], dtype=tf.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data scientist will load trained model to later be used for inference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching the list of root modules, please wait!\n",
      "(This will only be done once - type '%rehashx' to reset cache!)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = load_model('model_2.h5', custom_objects={'KerasLayer': pretrained_layer})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, data scientist will define dictionary to convert nominal to class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define class dictionary\n",
    "dict_class = {0: 'fantasy',\n",
    "              1: 'science',\n",
    "              2: 'crime',\n",
    "              3: 'history',\n",
    "              4: 'horror',\n",
    "              5: 'thriller',\n",
    "              6: 'psychology',\n",
    "              7: 'romance',\n",
    "              8: 'sports',\n",
    "              9: 'travel'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 4. Inference Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Define Inference Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data scientist will create inference data which the model has never been trained with before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4657</td>\n",
       "      <td>The Notebook</td>\n",
       "      <td>Noah and Allie spend a wonderful summer togeth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         title                                            summary\n",
       "0   4657  The Notebook  Noah and Allie spend a wonderful summer togeth..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create inference data\n",
    "inf_data = {'index': 4657,\n",
    "            'title': \"The Notebook\",\n",
    "            'summary': \"Noah and Allie spend a wonderful summer together, but her family and the socio-economic realities of the time prevent them from being together. Although Noah attempts to keep in contact with Allie after they are forced to separate, his letters go unanswered. Eventually, Noah professes his undying and eternal love in one final letter. Noah travels north to find gainful employment and to escape the ghost of Allie, and eventually he goes off to war. After serving his country, he returns home to restore an old farmhouse. A newspaper article about his endeavor catches Allie's eye, and 14 years after she last saw Noah, Allie returns to him. The only problem is she is engaged to another man. After spending two wonderful reunion days together, Allie must decide between the two men that she loves.\"}\n",
    "\n",
    "# put inference data into dataframe\n",
    "inf_data = pd.DataFrame(inf_data, index=[0])\n",
    "# show dataframe\n",
    "inf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, data scientist will use text_preprocessing function defined in steps above so that the model can process data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4657</td>\n",
       "      <td>The Notebook</td>\n",
       "      <td>Noah and Allie spend a wonderful summer togeth...</td>\n",
       "      <td>noah allie spend wonderful summer together fam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         title                                            summary  \\\n",
       "0   4657  The Notebook  Noah and Allie spend a wonderful summer togeth...   \n",
       "\n",
       "                                      text_processed  \n",
       "0  noah allie spend wonderful summer together fam...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_data['text_processed'] = inf_data['summary'].apply(lambda x: text_preprocessing(x))\n",
    "inf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "# calculate probability\n",
    "y_pred_inf = model.predict(inf_data.text_processed)\n",
    "# take class with biggest probability\n",
    "y_pred_inf_class = np.argmax(y_pred_inf, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fantasy</th>\n",
       "      <th>science</th>\n",
       "      <th>crime</th>\n",
       "      <th>history</th>\n",
       "      <th>horror</th>\n",
       "      <th>thriller</th>\n",
       "      <th>psychology</th>\n",
       "      <th>romance</th>\n",
       "      <th>sports</th>\n",
       "      <th>travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.194008</td>\n",
       "      <td>0.138966</td>\n",
       "      <td>0.104051</td>\n",
       "      <td>0.127359</td>\n",
       "      <td>0.112602</td>\n",
       "      <td>0.234017</td>\n",
       "      <td>0.023547</td>\n",
       "      <td>0.023245</td>\n",
       "      <td>0.019361</td>\n",
       "      <td>0.022844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fantasy   science     crime   history    horror  thriller  psychology  \\\n",
       "0  0.194008  0.138966  0.104051  0.127359  0.112602  0.234017    0.023547   \n",
       "\n",
       "    romance    sports    travel  \n",
       "0  0.023245  0.019361  0.022844  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show probability for each class\n",
    "y_pred_df = pd.DataFrame(y_pred_inf, columns=['fantasy', 'science', 'crime', 'history', 'horror', 'thriller', 'psychology', 'romance', 'sports', 'travel'])\n",
    "y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book Genre Prediction: thriller\n"
     ]
    }
   ],
   "source": [
    "# convert probability to class name\n",
    "print(f'Book Genre Prediction: {dict_class[int(y_pred_inf_class)]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
